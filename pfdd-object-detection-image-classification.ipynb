{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PFDD - Real-Time Object Detection + Image Classification with TensorFlow \n\nThis notebook is intended to provide a brief look into Computer Vision with enhanced transfer learning using TensorFlow.\n\n\nWhen it comes to CV tasks, PyTorch is my personal preference -as far as image classification and object detection are concerned. But with TF2's massive progession recently, as well as TFHub's open access to thousands of pre-trained models, the simplicity of generating accurate predictive results through transfer learning is a massive step forward in ML.","metadata":{}},{"cell_type":"code","source":"# modules used\nimport os\nimport pandas as pd\nimport numpy as np\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport posixpath\nimport cv2\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nfrom matplotlib import colors\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve\nfrom sklearn.model_selection import learning_curve, cross_val_score, GridSearchCV\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\nfrom keras_preprocessing.image import ImageDataGenerator\nimport tensorflow_hub as hub\nfrom sklearn.preprocessing import LabelBinarizer\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:17:52.564870Z","iopub.execute_input":"2021-10-30T16:17:52.565171Z","iopub.status.idle":"2021-10-30T16:17:58.465549Z","shell.execute_reply.started":"2021-10-30T16:17:52.565096Z","shell.execute_reply":"2021-10-30T16:17:58.464756Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Image data - Directory and path","metadata":{}},{"cell_type":"code","source":"# image file names + extensions\nimages = os.listdir(\"../input/train-images/Train_Images\")\n\n# image directory\nimage_directory = Path('../input/train-images/Train_Images')\n\n# image full path\nimage_filepaths = list(image_directory.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:19:21.573797Z","iopub.execute_input":"2021-10-30T16:19:21.574056Z","iopub.status.idle":"2021-10-30T16:19:27.323979Z","shell.execute_reply.started":"2021-10-30T16:19:21.574029Z","shell.execute_reply":"2021-10-30T16:19:27.323237Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# append all image names to list\nimages_list = []\n\nfor f in images:  \n    exc_name = f.split('/')[-1].split(',')\n    images_list.append(''.join(exc_name))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:19:40.698569Z","iopub.execute_input":"2021-10-30T16:19:40.699337Z","iopub.status.idle":"2021-10-30T16:19:40.706793Z","shell.execute_reply.started":"2021-10-30T16:19:40.699292Z","shell.execute_reply":"2021-10-30T16:19:40.704748Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The data used had a dataframe with all the image ids and their respective labels","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/ffpd-od/Train (6).csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:21:40.036140Z","iopub.execute_input":"2021-10-30T16:21:40.036907Z","iopub.status.idle":"2021-10-30T16:21:40.072908Z","shell.execute_reply.started":"2021-10-30T16:21:40.036854Z","shell.execute_reply":"2021-10-30T16:21:40.072217Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Extracting the id from the image name\nmapping = {f.split(\".\")[0]: f for f in images_list} \ntrain['img_names'] = pd.Series() \n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:23:44.604966Z","iopub.execute_input":"2021-10-30T16:23:44.605229Z","iopub.status.idle":"2021-10-30T16:23:44.621892Z","shell.execute_reply.started":"2021-10-30T16:23:44.605201Z","shell.execute_reply":"2021-10-30T16:23:44.621185Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for image_id, img_filename in mapping.items():\n    train.loc[train.Image_ID == image_id, \"img_names\"] = img_filename","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:23:52.838183Z","iopub.execute_input":"2021-10-30T16:23:52.838960Z","iopub.status.idle":"2021-10-30T16:23:55.898144Z","shell.execute_reply.started":"2021-10-30T16:23:52.838923Z","shell.execute_reply":"2021-10-30T16:23:55.897440Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"*Terrible of me to partition my code into these many little cells. \nUncharacteristic on my part, but unacceptable behavior nonetheless.*","metadata":{}},{"cell_type":"code","source":"# some visuals\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(posixpath.join(image_directory, train.img_names[i])))\n    ax.set_title(train['class'][i], color=\"white\")\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:29:26.982104Z","iopub.execute_input":"2021-10-30T16:29:26.982479Z","iopub.status.idle":"2021-10-30T16:29:28.744980Z","shell.execute_reply.started":"2021-10-30T16:29:26.982441Z","shell.execute_reply":"2021-10-30T16:29:28.743675Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Some EDA..","metadata":{}},{"cell_type":"code","source":"!pip install dataprep\nfrom dataprep.eda import create_report\ncreate_report(train)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:31:35.173747Z","iopub.execute_input":"2021-10-30T16:31:35.174015Z","iopub.status.idle":"2021-10-30T16:32:02.248200Z","shell.execute_reply.started":"2021-10-30T16:31:35.173986Z","shell.execute_reply":"2021-10-30T16:32:02.247219Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train = train.rename(columns={'class': 'fruit_class'})","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:32:28.044802Z","iopub.execute_input":"2021-10-30T16:32:28.045492Z","iopub.status.idle":"2021-10-30T16:32:28.052046Z","shell.execute_reply.started":"2021-10-30T16:32:28.045448Z","shell.execute_reply":"2021-10-30T16:32:28.051338Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# image processing\n\n# experiment\nimg_healthy = cv2.imread(posixpath.join(image_directory, train.img_names[22]))\nimg_woody = cv2.imread(posixpath.join(image_directory, train.img_names[74]))\nimg_spotty = cv2.imread(posixpath.join(image_directory, train.img_names[33]))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:33:10.566514Z","iopub.execute_input":"2021-10-30T16:33:10.567338Z","iopub.status.idle":"2021-10-30T16:33:10.643997Z","shell.execute_reply.started":"2021-10-30T16:33:10.567282Z","shell.execute_reply":"2021-10-30T16:33:10.643294Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15,15))\naxes[0].imshow(img_healthy)\naxes[0].set_title(\"Healthy\", fontsize = 18)\n \naxes[1].imshow(img_woody)\naxes[1].set_title(\"Woody\", fontsize = 18)\n\naxes[2].imshow(img_spotty)\naxes[2].set_title(\"Spotty\", fontsize = 18)\n\n    \nplt.show()\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:34:45.151990Z","iopub.execute_input":"2021-10-30T16:34:45.152663Z","iopub.status.idle":"2021-10-30T16:34:45.765378Z","shell.execute_reply.started":"2021-10-30T16:34:45.152611Z","shell.execute_reply":"2021-10-30T16:34:45.764714Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# plot the hue channel\nimg_healthy_hsv = cv2.cvtColor(img_healthy, cv2.COLOR_RGB2HSV)\nimg_woody_hsv = cv2.cvtColor(img_woody, cv2.COLOR_RGB2HSV)\nimg_spotty_hsv = cv2.cvtColor(img_spotty, cv2.COLOR_RGB2HSV)\n\nhue_healthy = img_healthy_hsv[:,:,0]\nhue_woody = img_woody_hsv[:,:,0]\nhue_spotty = img_spotty_hsv[:,:,0]\n\nfig, axes = plt.subplots(1, 3, figsize=(15,15))\naxes[0].imshow(hue_healthy)\naxes[0].set_title(\"Healthy\", fontsize = 18)\n \naxes[1].imshow(hue_woody)\naxes[1].set_title(\"Woody\", fontsize = 18)\n\naxes[2].imshow(hue_spotty)\naxes[2].set_title(\"Spotty\", fontsize = 18)\n\n    \nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:34:54.665158Z","iopub.execute_input":"2021-10-30T16:34:54.665875Z","iopub.status.idle":"2021-10-30T16:34:55.225636Z","shell.execute_reply.started":"2021-10-30T16:34:54.665838Z","shell.execute_reply":"2021-10-30T16:34:55.224956Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Green. Green everywhere.","metadata":{}},{"cell_type":"code","source":"hist_h, _ = np.histogram(hue_healthy, bins = 180, normed = False)\nplt.title(\"Hue Histogram\")\nplt.plot(hist_h)\nplt.show()\n\nhist_w, _ = np.histogram(hue_woody, bins = 180, normed = False)\nplt.title(\"Hue Histogram\")\nplt.plot(hist_w)\nplt.show()\n\nhist_s, _ = np.histogram(hue_spotty, bins = 180, normed = False)\nplt.title(\"Hue Histogram\")\nplt.plot(hist_s)\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:36:07.924088Z","iopub.execute_input":"2021-10-30T16:36:07.924801Z","iopub.status.idle":"2021-10-30T16:36:08.493857Z","shell.execute_reply.started":"2021-10-30T16:36:07.924754Z","shell.execute_reply":"2021-10-30T16:36:08.493099Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Almost all the pixel values are concentrated around the green channel. 70 - 120.","metadata":{}},{"cell_type":"code","source":"# removing all the colored channels\nimg_healthy_gray = cv2.cvtColor(img_healthy, cv2.COLOR_BGR2GRAY)\nimg_woody_gray = cv2.cvtColor(img_woody, cv2.COLOR_BGR2GRAY)\nimg_spotty_gray = cv2.cvtColor(img_spotty, cv2.COLOR_BGR2GRAY)\n\nfig, axes = plt.subplots(1, 3, figsize=(15,15))\naxes[0].imshow(img_healthy_gray, cmap='gray')\naxes[0].set_title(\"Healthy\", fontsize = 18)\n \naxes[1].imshow(img_woody_gray, cmap='gray')\naxes[1].set_title(\"Woody\", fontsize = 18)\n\naxes[2].imshow(img_spotty_gray, cmap='gray')\naxes[2].set_title(\"Spotty\", fontsize = 18)\n\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:39:15.033641Z","iopub.execute_input":"2021-10-30T16:39:15.034188Z","iopub.status.idle":"2021-10-30T16:39:15.549472Z","shell.execute_reply.started":"2021-10-30T16:39:15.034151Z","shell.execute_reply":"2021-10-30T16:39:15.548809Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Color transformations below; not to much effect","metadata":{}},{"cell_type":"code","source":"img_healthy_hsv = cv2.cvtColor(img_healthy, cv2.COLOR_BGR2HSV)\nimg_woody_hsv = cv2.cvtColor(img_woody, cv2.COLOR_BGR2HSV)\nimg_spotty_hsv = cv2.cvtColor(img_spotty, cv2.COLOR_BGR2HSV)\n\nhue_h = img_healthy_hsv[:,:,0]\nhue_w = img_woody_hsv[:,:,0]\nhue_s = img_spotty_hsv[:,:,0]\n\nval_h = img_healthy_hsv[:,:,2]\nval_w = img_woody_hsv[:,:,2]\nval_s = img_spotty_hsv[:,:,2]\n\nsat_h = img_healthy_hsv[:,:,1]\nsat_w = img_woody_hsv[:,:,1]\nsat_s = img_spotty_hsv[:,:,1]\n\n\nhue_h = hue_h + 10\nhue_w = hue_w + 10\nhue_s = hue_s - 100\n\nval_h = val_h * 0.6\nval_w = val_w * 0.3\nval_s = val_s * 1.6\n\nsat_h = sat_h - 96\nsat_w = sat_w - 96\nsat_s = sat_s + 96\n\ncond_h = hue_h[:, :] < 0\nhue_h[cond_h] = 0\n\ncnd_h = val_h[:,:] > 255\nval_h[cnd_h] = 255\n\ncond_w = hue_w[:, :] < 0\nhue_w[cond_w] = 0\n\ncnd_w = val_w[:,:] > 255\nval_w[cnd_w] = 255\n\ncond_s = hue_s[:, :] < 0\nhue_s[cond_s] = 0\n\ncnd_s = val_s[:,:] > 255\nval_s[cnd_s] = 255\n\nimg_healthy_hsv[:,:,0] = hue_h\nimg_woody_hsv[:,:,0] = hue_w\nimg_spotty_hsv[:,:,0] = hue_s\n\nimg_healthy_hsv[:,:,2] = val_h\nimg_woody_hsv[:,:,2] = val_w\nimg_spotty_hsv[:,:,2] = val_s\n\n\nimg_healthy_rgb = cv2.cvtColor(img_healthy_hsv, cv2.COLOR_HSV2RGB)\nimg_woody_rgb = cv2.cvtColor(img_woody_hsv, cv2.COLOR_HSV2RGB)\nimg_spotty_rgb = cv2.cvtColor(img_spotty_hsv, cv2.COLOR_HSV2RGB)\n\nimg_healthy_gray = cv2.cvtColor(img_healthy_rgb, cv2.COLOR_RGB2GRAY)\nimg_woody_gray = cv2.cvtColor(img_woody_rgb, cv2.COLOR_RGB2GRAY)\nimg_spotty_gray = cv2.cvtColor(img_spotty_rgb, cv2.COLOR_RGB2GRAY)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:42:11.470881Z","iopub.execute_input":"2021-10-30T16:42:11.471731Z","iopub.status.idle":"2021-10-30T16:42:11.502012Z","shell.execute_reply.started":"2021-10-30T16:42:11.471689Z","shell.execute_reply":"2021-10-30T16:42:11.501306Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"r, g, b = cv2.split(img_healthy_rgb)\nfig = plt.figure()\naxis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n\npixel_colors = img_healthy_rgb.reshape((np.shape(img_healthy_rgb)[0]*np.shape(img_healthy_rgb)[1], 3))\nnorm = colors.Normalize(vmin=-1.,vmax=1.)\nnorm.autoscale(pixel_colors)\npixel_colors = norm(pixel_colors).tolist()\n\naxis.scatter(r.flatten(), g.flatten(), b.flatten(), facecolors=pixel_colors, marker=\".\")\naxis.set_xlabel(\"Red\")\naxis.set_ylabel(\"Green\")\naxis.set_zlabel(\"Blue\")\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:42:21.377055Z","iopub.execute_input":"2021-10-30T16:42:21.377324Z","iopub.status.idle":"2021-10-30T16:42:26.831847Z","shell.execute_reply.started":"2021-10-30T16:42:21.377294Z","shell.execute_reply":"2021-10-30T16:42:26.831128Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"img_healthy_gray = cv2.cvtColor(img_healthy_rgb, cv2.COLOR_RGB2GRAY)\nimg_woody_gray = cv2.cvtColor(img_woody_rgb, cv2.COLOR_RGB2GRAY)\nimg_spotty_gray = cv2.cvtColor(img_spotty_rgb, cv2.COLOR_RGB2GRAY)\n\nfig, axes = plt.subplots(1, 3, figsize=(15,15))\naxes[0].imshow(img_healthy_gray, cmap = \"gray\")\naxes[0].set_title(\"Healthy\", fontsize = 18)\n \naxes[1].imshow(img_woody_gray,  cmap = \"gray\")\naxes[1].set_title(\"Woody\", fontsize = 18)\n\naxes[2].imshow(img_spotty_gray,  cmap = \"gray\")\naxes[2].set_title(\"Spotty\", fontsize = 18)\n\n    \nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2021-10-30T16:42:36.098193Z","iopub.execute_input":"2021-10-30T16:42:36.098792Z","iopub.status.idle":"2021-10-30T16:42:36.849642Z","shell.execute_reply.started":"2021-10-30T16:42:36.098753Z","shell.execute_reply":"2021-10-30T16:42:36.848182Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Below were some write operations of the transformed images onto the disk","metadata":{}},{"cell_type":"code","source":"# for index, img in train.iterrows():          \n#     if (img['fruit_class'] == \"fruit_healthy\"):  \n#         path_h = cv2.imread(posixpath.join(image_directory, img.img_names))\n#         img_hsv = cv2.cvtColor(path_h, cv2.COLOR_BGR2HSV)\n#         hue_h = img_hsv[:,:,0]\n#         val_h = img_hsv[:,:,2]\n#         sat_h = img_hsv[:,:,1]\n#         hue_h = hue_h + 10\n#         val_h = val_h * 1.02\n\n#         cond_h = hue_h[:, :] < 0\n#         hue_h[cond_h] = 0\n\n#         cnd_h = val_h[:,:] > 255\n#         val_h[cnd_h] = 255\n\n#         img_hsv[:,:,0] = hue_h\n#         img_hsv[:,:,2] = val_h\n        \n#         img_rgb = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)   \n#         img_h_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) \n#         cv2.imwrite(\"/kaggle/working/\" + img.img_names, img_h_gray)\n        \n#     elif (img['fruit_class'] == \"fruit_woodiness\"):\n#         path_w = cv2.imread(posixpath.join(image_directory, img.img_names))\n#         img_woody_hsv = cv2.cvtColor(path_w, cv2.COLOR_BGR2HSV)\n#         hue_w = img_woody_hsv[:,:,0]\n#         val_w = img_woody_hsv[:,:,2]\n#         sat_w = img_woody_hsv[:,:,1]\n#         hue_w = hue_w - 20\n#         val_w = val_w * 1.03\n        \n#         cond_w = hue_w[:, :] < 0\n#         hue_w[cond_w] = 0\n\n#         cnd_w = val_w[:,:] > 255\n#         val_w[cnd_w] = 255\n        \n#         img_woody_hsv[:,:,0] = hue_w\n#         img_woody_hsv[:,:,2] = val_w\n        \n        \n#         img_woody_rgb = cv2.cvtColor(img_woody_hsv, cv2.COLOR_HSV2RGB)   \n#         img_w_gray = cv2.cvtColor(img_woody_rgb, cv2.COLOR_RGB2GRAY)\n#         cv2.imwrite(\"/kaggle/working/\" + img.img_names, img_w_gray)\n        \n#     else:\n#         path_s = cv2.imread(posixpath.join(image_directory, img.img_names))\n#         img_spotty_hsv = cv2.cvtColor(path_s, cv2.COLOR_BGR2HSV)\n#         hue_s = img_spotty_hsv[:,:,0]\n#         val_s = img_spotty_hsv[:,:,2]\n#         sat_s = img_spotty_hsv[:,:,1]\n#         hue_s = hue_s - 5\n#         val_s = val_s * 1.03\n        \n#         cond_s = hue_s[:, :] < 0\n#         hue_s[cond_s] = 0\n\n#         cnd_s = val_s[:,:] > 255\n#         val_s[cnd_s] = 255\n        \n#         img_spotty_hsv[:,:,0] = hue_s\n#         img_spotty_hsv[:,:,2] = val_s\n        \n#         img_spotty_rgb = cv2.cvtColor(img_spotty_hsv, cv2.COLOR_HSV2RGB)   \n#         img_s_gray = cv2.cvtColor(img_spotty_rgb, cv2.COLOR_RGB2GRAY)\n#         cv2.imwrite(\"/kaggle/working/\" + img.img_names, img_s_gray)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-10-21T07:32:53.502644Z","iopub.execute_input":"2021-10-21T07:32:53.50293Z","iopub.status.idle":"2021-10-21T07:34:06.46184Z","shell.execute_reply.started":"2021-10-21T07:32:53.502902Z","shell.execute_reply":"2021-10-21T07:34:06.460939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import glob\n# print(len(glob.glob(\"/kaggle/working/*\")))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T07:32:37.527054Z","iopub.status.idle":"2021-10-21T07:32:37.527491Z","shell.execute_reply.started":"2021-10-21T07:32:37.527266Z","shell.execute_reply":"2021-10-21T07:32:37.52729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outputdir = Path(\"/kaggle/working/\")\n# length = []\n# for file in outputdir.glob(r'**/*.jpg'):\n#     os.remove(file)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-24T17:06:58.680262Z","iopub.execute_input":"2021-10-24T17:06:58.680963Z","iopub.status.idle":"2021-10-24T17:06:58.794807Z","shell.execute_reply.started":"2021-10-24T17:06:58.680927Z","shell.execute_reply":"2021-10-24T17:06:58.793972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train, train_size=0.85, shuffle=True, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:47:35.730112Z","iopub.execute_input":"2021-10-30T16:47:35.730918Z","iopub.status.idle":"2021-10-30T16:47:35.739374Z","shell.execute_reply.started":"2021-10-30T16:47:35.730879Z","shell.execute_reply":"2021-10-30T16:47:35.738578Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/testcsv/Test (4).csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:47:40.227838Z","iopub.execute_input":"2021-10-30T16:47:40.228100Z","iopub.status.idle":"2021-10-30T16:47:40.251967Z","shell.execute_reply.started":"2021-10-30T16:47:40.228069Z","shell.execute_reply":"2021-10-30T16:47:40.251299Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_images = os.listdir(\"../input/testimages/Test_Images\")\ntest_image_directory = Path('../input/testimages/Test_Images')\ntest_image_filepaths = list(test_image_directory.glob(r'**/*.jpg'))\n\ntest_images_list = []\nfor f in test_images:  \n    exc_name = f.split('/')[-1].split(',')\n    test_images_list.append(''.join(exc_name))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:47:48.072382Z","iopub.execute_input":"2021-10-30T16:47:48.073128Z","iopub.status.idle":"2021-10-30T16:47:48.538092Z","shell.execute_reply.started":"2021-10-30T16:47:48.073090Z","shell.execute_reply":"2021-10-30T16:47:48.537397Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"mapping = {f.split(\".\")[0]: f for f in test_images_list} \ntest['img_names'] = pd.Series() ","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:47:53.447505Z","iopub.execute_input":"2021-10-30T16:47:53.448018Z","iopub.status.idle":"2021-10-30T16:47:53.454123Z","shell.execute_reply.started":"2021-10-30T16:47:53.447982Z","shell.execute_reply":"2021-10-30T16:47:53.453287Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for image_id, test_img_filename in mapping.items():\n    test.loc[test.Image_ID == image_id, \"img_names\"] = test_img_filename","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:48:03.349266Z","iopub.execute_input":"2021-10-30T16:48:03.349524Z","iopub.status.idle":"2021-10-30T16:48:03.934012Z","shell.execute_reply.started":"2021-10-30T16:48:03.349495Z","shell.execute_reply":"2021-10-30T16:48:03.933295Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:48:09.787093Z","iopub.execute_input":"2021-10-30T16:48:09.787419Z","iopub.status.idle":"2021-10-30T16:48:09.813906Z","shell.execute_reply.started":"2021-10-30T16:48:09.787380Z","shell.execute_reply":"2021-10-30T16:48:09.813034Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"3 channel input image arrays are converted to tensors before being fed into the pretrained TF models","metadata":{}},{"cell_type":"code","source":"# bounding boxes\norig_test_path = Path('../input/testimages/Test_Images')\nrgb_tensor_test = []\nrgb_images = []\n\nfor index, img in test.iterrows():\n    img = cv2.imread(posixpath.join(orig_test_path, img.img_names))\n    inp = cv2.resize(img, (512,512))\n    #Convert img to RGB\n    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n    rgb_images.append(rgb)\n    # COnverting to uint8\n    rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n    #Add dims to rgb_tensor\n    rgb_tensor = tf.expand_dims(rgb_tensor, 0)\n    rgb_tensor_test.append(rgb_tensor)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:49:40.870044Z","iopub.execute_input":"2021-10-30T16:49:40.870319Z","iopub.status.idle":"2021-10-30T16:49:58.409559Z","shell.execute_reply.started":"2021-10-30T16:49:40.870289Z","shell.execute_reply":"2021-10-30T16:49:58.408627Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Faster RCNN Resnetv1\nPretrained on the ImageNet dataset. Decent running time as well, as shown after execution","metadata":{}},{"cell_type":"code","source":"import time\ndetector = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1\")\npred_labels = []\npred_boxes = []\npred_scores = []\npred_kps = []\n\nstart = time.time()\nfor rgbTensor in rgb_tensor_test:\n    detector_output = detector(rgbTensor)\n    class_ids = detector_output[\"detection_classes\"]\n    boxes = detector_output[\"detection_boxes\"]\n    pred_boxes.append(boxes.numpy()[0])\n    scores = detector_output[\"detection_scores\"]\n    pred_scores.append(scores.numpy()[0])\nend = time.time()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:52:27.744097Z","iopub.execute_input":"2021-10-30T16:52:27.744890Z","iopub.status.idle":"2021-10-30T16:56:08.276384Z","shell.execute_reply.started":"2021-10-30T16:52:27.744840Z","shell.execute_reply":"2021-10-30T16:56:08.275630Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(end - start)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:56:25.890448Z","iopub.execute_input":"2021-10-30T16:56:25.890979Z","iopub.status.idle":"2021-10-30T16:56:25.897569Z","shell.execute_reply.started":"2021-10-30T16:56:25.890943Z","shell.execute_reply":"2021-10-30T16:56:25.896817Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Not too bad. There's only less than 3000 images, but with 512x512 dimensionality","metadata":{}},{"cell_type":"markdown","source":"2nd model should be significantly slower.A mask rcnn implementation of v2 Inception Resnet pretrained on the COCO dataset","metadata":{}},{"cell_type":"code","source":"#2\n\ndetector = hub.load(\"https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1\")\n\n\npred_labels2 = []\npred_boxes2 = []\npred_scores2 = []\n\nstart2 = time.time()\nfor rgbTensor in rgb_tensor_test:\n    detector_output = detector(rgbTensor)\n    class_ids = detector_output[\"detection_classes\"]\n    boxes2 = detector_output[\"detection_boxes\"]\n    pred_boxes2.append(boxes2.numpy())\n    scores2 = detector_output[\"detection_scores\"]\n    pred_scores2.append(scores2.numpy())\nend = time.time()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:58:26.681928Z","iopub.execute_input":"2021-10-30T16:58:26.682202Z","iopub.status.idle":"2021-10-30T17:07:40.773553Z","shell.execute_reply.started":"2021-10-30T16:58:26.682173Z","shell.execute_reply":"2021-10-30T17:07:40.772721Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(end - start2)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:07:50.747607Z","iopub.execute_input":"2021-10-30T17:07:50.747876Z","iopub.status.idle":"2021-10-30T17:07:50.752179Z","shell.execute_reply.started":"2021-10-30T17:07:50.747847Z","shell.execute_reply":"2021-10-30T17:07:50.751312Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"pred_boxes2[0][0][:3]","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:08:18.029832Z","iopub.execute_input":"2021-10-30T17:08:18.030091Z","iopub.status.idle":"2021-10-30T17:08:18.036662Z","shell.execute_reply.started":"2021-10-30T17:08:18.030062Z","shell.execute_reply":"2021-10-30T17:08:18.035879Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"pred_scores2[5][0][:2]","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:08:26.875989Z","iopub.execute_input":"2021-10-30T17:08:26.876373Z","iopub.status.idle":"2021-10-30T17:08:26.882615Z","shell.execute_reply.started":"2021-10-30T17:08:26.876329Z","shell.execute_reply":"2021-10-30T17:08:26.881812Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"lots of column and string formatting to get each bounding measurement into the right place","metadata":{}},{"cell_type":"code","source":"# test_rep = test_n[test_n['confidence'].str.contains(\" \")]\n# test_rem = test_n[~test_n['confidence'].str.contains(\" \")]\n# test_rep[\"confidence\"] = test_rep[\"confidence\"].str.replace(r'\\[', '')\n# test_rep[\"confidence\"] = test_rep[\"confidence\"].str.replace(r'\\]', '')\n\n# conf_conv = []\n# for conf in test_rep['confidence']:\n#     conf_conv.append(Convert(conf))\n    \n# confidences = []\n# for str_list in conf_conv:\n#     str_list_fil = list(filter(None, str_list))\n#     confidences.append(str_list_fil)\n\n# conf_lens = []\n# for conflen in confidences:\n#     length = len(conflen)\n#     conf_lens.append(length)\n    \n# dup_ids = test_rep['Image_ID'].repeat(conf_lens)\n# conf_finale = []\n# for cnf in confidences:\n#     for c in cnf:\n#         conf_finale.append(c)\n        \n# boxes_in_list = []\n# for bounds in test_rep['boxes']:\n#     b = bounds.replace('[[', '')\n#     b2 = b.replace(']', '')\n#     b3 = b2.replace('[', '')\n#     b4 = ConvertBoxes(b3)\n#     boxes_in_list.append(b4)\n    \n# boxes_finale = []\n# for box in boxes_in_list:\n#     for item in box:\n#         boxes_finale.append(item)\n        \n# conf_final = []\n# for c_num in conf_finale:\n#     new_c = c_num.replace(']', '')\n#     new_c2 = new_c.replace('[', '') \n#     new_c3 = new_c2.replace(\"''\", '')\n#     new_c4 = float(new_c3)\n#     conf_final.append(new_c4)\n    \n# boxes_final = []\n# for bx in boxes_finale:\n#     new_bx = list(bx.split(' '))\n#     boxes_final.append(new_bx)\n    \n# x_min = []\n# y_min = []\n# x_max = []\n# y_max = []\n# newbx_final = []\n\n# for box_item in boxes_final:\n#     box_item_new = list(filter(None, box_item))\n#     newbx_final.append(box_item_new)\n    \n# for newbx in newbx_final:\n#         x_min.append(float(newbx[0]))\n#         y_min.append(float(newbx[1]))\n#         x_max.append(float((newbx[2]))\n#         y_max.append(float((newbx[3]))\n        \n# rem_conf = test_rem['confidence']\n# rem_conf_finale = []\n# for rem_c in rem_conf:\n#     rem_c_new =  rem_c.replace('[', '')\n#     rem_c_new2 =  rem_c_new.replace(']', '')\n#     rem_conf_finale.append(rem_c_new2)\n    \n# rem_conf_final = []\n# for rc in rem_conf_finale:\n#     rc_new = rc.replace(\"''\", '')\n#     rc_f_new = float(rc_new)\n#     rem_conf_final.append(rc_f_new)\n    \n# rem_boxes = test_rem['boxes']\n# rem_boxes_finale = []\n\n# for rem_box in rem_boxes:\n#     rb_new = rem_box.replace(\"[[\", '')\n#     rc_new2 = rb_new.replace(\"]]\", '')\n#     rem_boxes_finale.append(rc_new2)\n\n# rem_boxes_final = []\n\n# for rem_bx in rem_boxes_finale:\n#     rem_new_bx = list(rem_bx.split(' '))\n#     rem_boxes_final.append(rem_new_bx)\n    \n# x_min2 = []\n# y_min2 = []\n# x_max2 = []\n# y_max2 = []\n# newrembx_final = []\n\n# for rem_box_item in rem_boxes_final:\n#     rem_box_item_new = list(filter(None, rem_box_item))\n#     newrembx_final.append(rem_box_item_new)\n    \n# for newrembx in newrembx_final:\n#         x_min2.append(float(newrembx[0]))\n#         y_min2.append(float(newrembx[1]))\n#         x_max2.append(float(newrembx[2]))\n#         y_max2.append(float(newrembx[3]))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T17:38:58.50213Z","iopub.execute_input":"2021-10-27T17:38:58.502783Z","iopub.status.idle":"2021-10-27T17:38:58.544698Z","shell.execute_reply.started":"2021-10-27T17:38:58.502729Z","shell.execute_reply":"2021-10-27T17:38:58.543609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = os.listdir(\"../input/testimages/Test_Images\")\ntest_image_directory = Path('../input/testimages/Test_Images')\ntest_image_filepaths = list(test_image_directory.glob(r'**/*.jpg'))\n\ntest_images_list = []\nfor f in test_images:  \n    exc_name = f.split('/')[-1].split(',')\n    test_images_list.append(''.join(exc_name))\n    \nmapping = {f.split(\".\")[0]: f for f in test_images_list} \ntest['img_names'] = pd.Series() \n\nfor image_id, test_img_filename in mapping.items():\n    test.loc[test.Image_ID == image_id, \"img_names\"] = test_img_filename","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:27:47.580084Z","iopub.execute_input":"2021-10-30T17:27:47.580364Z","iopub.status.idle":"2021-10-30T17:27:48.202068Z","shell.execute_reply.started":"2021-10-30T17:27:47.580334Z","shell.execute_reply":"2021-10-30T17:27:48.201378Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Reduced the image sizes before feeding them into the classifier networks","metadata":{}},{"cell_type":"code","source":"# for index, img in test.iterrows():   \n#         path = cv2.imread(posixpath.join(test_image_directory, img.img_names))\n#         img_hsv = cv2.cvtColor(path, cv2.COLOR_BGR2HSV)\n#         hue = img_hsv[:,:,0]\n#         val = img_hsv[:,:,2]\n#         hue = hue + 10\n#         val = val * 1.02\n\n#         cond = hue[:, :] < 0\n#         hue[cond] = 0\n\n#         cnd = val[:,:] > 255\n#         val[cnd] = 255\n\n#         img_hsv[:,:,0] = hue\n#         img_hsv[:,:,2] = val\n        \n#         img_rgb = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)   \n#         img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY) \n#         cv2.imwrite(\"/kaggle/working/\" + img.img_names, img_gray)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train resize\n# train_paths = Path('../input/passion-fruit-disease-detection/Train_Images/Train_Images')\n# train_image_filepaths = list(train_paths.glob(r'**/*.jpg'))\n# train_fps = str(train_image_filepaths)\n# resized_imgs = []\n\n# for index, img in train.iterrows():\n#     train_image = cv2.imread(posixpath.join(train_paths, img.img_names), cv2.IMREAD_UNCHANGED)\n#     resized_train = cv2.resize(train_image, (128,128), interpolation = cv2.INTER_AREA)\n#     resized_train_rgb = cv2.cvtColor(resized_train, cv2.COLOR_BGR2RGB)\n#     resized_imgs.append(resized_train_rgb)\n#     cv2.imwrite(\"/kaggle/working/\" + img.img_names, resized_train)\n    \n# print(resized_imgs[0].shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T17:03:22.660754Z","iopub.execute_input":"2021-10-24T17:03:22.661019Z","iopub.status.idle":"2021-10-24T17:04:09.201525Z","shell.execute_reply.started":"2021-10-24T17:03:22.660989Z","shell.execute_reply":"2021-10-24T17:04:09.200813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test resize\n# test_paths = Path('../input/test-images/Test_Images')\n# resized_test = []\n\n# for index, img in test.iterrows():\n#     test_image = cv2.imread(posixpath.join(test_paths, img.img_names), cv2.IMREAD_UNCHANGED)\n#     res_test = cv2.resize(test_image, (128,128), interpolation = cv2.INTER_AREA)\n#     resized_test_rgb = cv2.cvtColor(res_test, cv2.COLOR_BGR2RGB)\n#     resized_test.append(resized_test_rgb)\n#     cv2.imwrite(\"/kaggle/working/\" + img.img_names, res_test)\n    \n# print(resized_test[0].shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T19:06:25.0652Z","iopub.execute_input":"2021-10-23T19:06:25.065767Z","iopub.status.idle":"2021-10-23T19:06:36.563662Z","shell.execute_reply.started":"2021-10-23T19:06:25.065727Z","shell.execute_reply":"2021-10-23T19:06:36.562906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_train_dir = Path('../input/resizedtrainimgs/resized_train 128x128')\ntrain_dir = Path('../input/after-imgs/After Images')\nres_test_dir = Path('../input/resizedtest/resized_test 128x128')\ntest_dir = Path('../input/after-imgs/After Images')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:27:56.992042Z","iopub.execute_input":"2021-10-30T17:27:56.992368Z","iopub.status.idle":"2021-10-30T17:27:56.996271Z","shell.execute_reply.started":"2021-10-30T17:27:56.992336Z","shell.execute_reply":"2021-10-30T17:27:56.995536Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# modelling\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range = 30, zoom_range = 0.20, \n    fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \n    width_shift_range = 0.1, height_shift_range = 0.1,\n    validation_split=0.15)\n\n\ntestgen = tf.keras.preprocessing.image.ImageDataGenerator(\n   rotation_range = 20, zoom_range = 0.1, \n    fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \n    width_shift_range = 0.1, height_shift_range = 0.1\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T17:28:07.400000Z","iopub.execute_input":"2021-10-30T17:28:07.400291Z","iopub.status.idle":"2021-10-30T17:28:07.407077Z","shell.execute_reply.started":"2021-10-30T17:28:07.400240Z","shell.execute_reply":"2021-10-30T17:28:07.406219Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_generator=datagen.flow_from_dataframe(dataframe=train_df,\n                                            directory=res_train_dir, \n                                            x_col=\"img_names\", \n                                            y_col=\"fruit_class\",\n                                            class_mode=\"categorical\", \n                                            color_mode=\"grayscale\",\n                                            target_size=(128,128),\n                                            batch_size=32,\n                                            shuffle=True,\n                                            seed=42,\n                                            subset='training')","metadata":{"execution":{"iopub.status.busy":"2021-10-25T02:33:26.423667Z","iopub.execute_input":"2021-10-25T02:33:26.424431Z","iopub.status.idle":"2021-10-25T02:33:33.809315Z","shell.execute_reply.started":"2021-10-25T02:33:26.424389Z","shell.execute_reply":"2021-10-25T02:33:33.808577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will choose not to run any of these models, despite the short times they generally took.\n\nVery high accuracies were observed. Might have overfit the data several times, however the classifier models did not generate the best results - as per my expectations. They are not pretrained models hence it is moderately understandable\n\nHowever the last classifier network was pretrained.The Xception model provided by Keras. This model has been a success for me in the past but in this specific data, everything that was not PyTorch implemented proved problematic - to say the least\n","metadata":{}},{"cell_type":"code","source":"val_generator=datagen.flow_from_dataframe(dataframe=train_df,\n                                          directory=res_train_dir, \n                                          x_col=\"img_names\", \n                                          y_col=\"fruit_class\",\n                                          class_mode=\"categorical\",\n                                          color_mode=\"grayscale\",\n                                          target_size=(128,128),\n                                          batch_size=32,\n                                          shuffle=True,\n                                          seed=42,\n                                          subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:31:51.25854Z","iopub.execute_input":"2021-10-24T15:31:51.258798Z","iopub.status.idle":"2021-10-24T15:31:52.073571Z","shell.execute_reply.started":"2021-10-24T15:31:51.25877Z","shell.execute_reply":"2021-10-24T15:31:52.072766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator=testgen.flow_from_dataframe(dataframe=val_df,\n                                           directory=res_train_dir, \n                                           x_col=\"img_names\", \n                                           y_col=\"fruit_class\",\n                                           class_mode=\"categorical\", \n                                           color_mode=\"grayscale\",\n                                           target_size=(128,128),\n                                           batch_size=32,\n                                           shuffle=False\n                                           )","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:34:38.89178Z","iopub.execute_input":"2021-10-24T15:34:38.892471Z","iopub.status.idle":"2021-10-24T15:34:39.185014Z","shell.execute_reply.started":"2021-10-24T15:34:38.892432Z","shell.execute_reply":"2021-10-24T15:34:39.184233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_test = []\n\nfor index, img in val_df.iterrows():\n    test_image = cv2.imread(posixpath.join(res_train_dir, img.img_names), cv2.IMREAD_UNCHANGED)\n    resized_test.append(test_image)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T14:45:38.520296Z","iopub.execute_input":"2021-10-24T14:45:38.520605Z","iopub.status.idle":"2021-10-24T14:45:40.177667Z","shell.execute_reply.started":"2021-10-24T14:45:38.520574Z","shell.execute_reply":"2021-10-24T14:45:40.176637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First classifier. Simple. Basic. Terribly high variance.","metadata":{}},{"cell_type":"code","source":"# classifier 1\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32, (7, 7), padding='same',\n                 input_shape=(128,128,1), kernel_regularizer=l2(0.0005)))\nmodel.add(Activation('relu'))\nmodel.add(tf.keras.layers.Conv2D(64, (5, 5), kernel_regularizer=l2(0.0005)))\nmodel.add(Activation('relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', kernel_regularizer=l2(0.0005)))\nmodel.add(Activation('relu'))\nmodel.add(tf.keras.layers.Conv2D(256, (5, 5), kernel_regularizer=l2(0.0005)))\nmodel.add(Activation('relu'))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nopt = Adam(lr=1e-4)\nmodel.compile(optimizer=opt,\nloss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-25T08:09:13.785007Z","iopub.execute_input":"2021-10-25T08:09:13.785317Z","iopub.status.idle":"2021-10-25T08:09:13.793197Z","shell.execute_reply.started":"2021-10-25T08:09:13.785281Z","shell.execute_reply":"2021-10-25T08:09:13.792046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:32:32.374607Z","iopub.execute_input":"2021-10-24T15:32:32.375403Z","iopub.status.idle":"2021-10-24T15:32:32.389165Z","shell.execute_reply.started":"2021-10-24T15:32:32.375338Z","shell.execute_reply":"2021-10-24T15:32:32.388416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import Callback, EarlyStopping\n\nmy_callbacks  = [EarlyStopping(monitor='val_accuracy',\n                              min_delta=0,\n                              verbose=1,\n                              patience=5,\n                              mode='auto')]\n\n\nmodel.fit(train_generator, \n          validation_data=test_generator,\n          epochs=10,\n          callbacks=my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T08:09:38.742173Z","iopub.execute_input":"2021-10-25T08:09:38.743101Z","iopub.status.idle":"2021-10-25T08:09:38.748284Z","shell.execute_reply.started":"2021-10-25T08:09:38.743046Z","shell.execute_reply":"2021-10-25T08:09:38.747391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test_generator, verbose=1)\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:38:18.398836Z","iopub.execute_input":"2021-10-24T15:38:18.399597Z","iopub.status.idle":"2021-10-24T15:38:19.780516Z","shell.execute_reply.started":"2021-10-24T15:38:18.399545Z","shell.execute_reply":"2021-10-24T15:38:19.779552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:42:53.890669Z","iopub.execute_input":"2021-10-24T15:42:53.890966Z","iopub.status.idle":"2021-10-24T15:42:53.896352Z","shell.execute_reply.started":"2021-10-24T15:42:53.890936Z","shell.execute_reply":"2021-10-24T15:42:53.89525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_generator)\npreds = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:46:13.563489Z","iopub.execute_input":"2021-10-24T15:46:13.564052Z","iopub.status.idle":"2021-10-24T15:46:15.209842Z","shell.execute_reply.started":"2021-10-24T15:46:13.564016Z","shell.execute_reply":"2021-10-24T15:46:15.209043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npreds = [labels[k] for k in preds]","metadata":{"execution":{"iopub.status.busy":"2021-10-24T15:46:42.023186Z","iopub.execute_input":"2021-10-24T15:46:42.02344Z","iopub.status.idle":"2021-10-24T15:46:42.027828Z","shell.execute_reply.started":"2021-10-24T15:46:42.023412Z","shell.execute_reply":"2021-10-24T15:46:42.027161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_rgb = Path('../input/train-resized-imgs/resized_train_rgb_128x128')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:33:24.405611Z","iopub.execute_input":"2021-10-27T18:33:24.405964Z","iopub.status.idle":"2021-10-27T18:33:24.411493Z","shell.execute_reply.started":"2021-10-27T18:33:24.405931Z","shell.execute_reply":"2021-10-27T18:33:24.410444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen_rgb = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255, rotation_range = 30, zoom_range = 0.20, \n    fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \n    width_shift_range = 0.1, height_shift_range = 0.1,\n    validation_split=0.15)\n\ntestgen_rgb = tf.keras.preprocessing.image.ImageDataGenerator(\n   rescale = 1./255\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:32:48.922942Z","iopub.execute_input":"2021-10-27T18:32:48.923256Z","iopub.status.idle":"2021-10-27T18:32:48.929837Z","shell.execute_reply.started":"2021-10-27T18:32:48.923225Z","shell.execute_reply":"2021-10-27T18:32:48.9288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second classifier. Similar to first. Only changes were the activation function and the optimizer. Also additional KFold CV. Better. Still not good","metadata":{}},{"cell_type":"code","source":"from keras.layers import Activation, Dense, Flatten, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import EarlyStopping, Callback\n\nkf = KFold(n_splits=3, shuffle=True, random_state=2021)\nX = np.array(train_df['img_names'])\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print('-'*10, '>', f'Fold {fold + 1}', '<', '-'*10)\n        \n        X_train, X_valid = X[train_idx], X[test_idx]\n        train_X_df = train_df.loc[train_df[\"img_names\"].isin(list(X_train))]\n        valid_X_df = train_df.loc[train_df[\"img_names\"].isin(list(X_valid))]\n        \n        train_generator_rgb = datagen_rgb.flow_from_dataframe(dataframe=train_X_df,\n                                                             directory=train_rgb, \n                                                             x_col=\"img_names\", \n                                                             y_col=\"fruit_class\",\n                                                             class_mode=\"categorical\", \n                                                             color_mode=\"rgb\",\n                                                             target_size=(128,128),\n                                                             batch_size=32,\n                                                             shuffle=True,\n                                                             seed=42,\n                                                             subset='training'\n                                                             )\n\n        val_generator_rgb = datagen_rgb.flow_from_dataframe(dataframe=train_X_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=True,\n                                                            seed=42,\n                                                            subset='validation',\n                                                            )\n\n        test_generator_rgb = testgen_rgb.flow_from_dataframe(dataframe=valid_X_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=False\n                                                            )\n        \n        model = tf.keras.Sequential()\n        model.add(tf.keras.layers.Conv2D(32, (7, 7), padding='same',\n                         input_shape=(128,128,3), kernel_regularizer=l2(0.0005)))\n        model.add(LeakyReLU())\n        model.add(tf.keras.layers.Conv2D(64, (5, 5), kernel_regularizer=l2(0.0005)))\n        model.add(LeakyReLU())\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n\n        model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', kernel_regularizer=l2(0.0005)))\n        model.add(LeakyReLU())\n        model.add(tf.keras.layers.Conv2D(256, (5, 5), kernel_regularizer=l2(0.0005)))\n        model.add(LeakyReLU())\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(256))\n        model.add(LeakyReLU())\n        model.add(Dropout(0.5))\n        model.add(Dense(3, activation='softmax'))\n\n        opt = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n        model.compile(optimizer=opt,\n        loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n        \n        my_callbacks = [EarlyStopping(monitor='val_accuracy',\n                               min_delta=0,\n                               verbose=1,\n                               patience=5,\n                               mode='auto')]\n\n\n        model.fit(train_generator_rgb, \n                  validation_data=val_generator_rgb,\n                  epochs=10,\n                  callbacks=my_callbacks)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:33:41.063476Z","iopub.execute_input":"2021-10-27T18:33:41.063763Z","iopub.status.idle":"2021-10-27T18:41:45.054002Z","shell.execute_reply.started":"2021-10-27T18:33:41.063731Z","shell.execute_reply":"2021-10-27T18:41:45.052899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T13:17:38.63462Z","iopub.execute_input":"2021-10-25T13:17:38.635184Z","iopub.status.idle":"2021-10-25T13:17:38.646666Z","shell.execute_reply.started":"2021-10-25T13:17:38.635147Z","shell.execute_reply":"2021-10-25T13:17:38.645781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(val_generator_rgb)\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:44:13.057016Z","iopub.execute_input":"2021-10-27T18:44:13.057351Z","iopub.status.idle":"2021-10-27T18:44:15.809888Z","shell.execute_reply.started":"2021-10-27T18:44:13.057319Z","shell.execute_reply":"2021-10-27T18:44:15.809009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(sub_generator_rgb)\npreds_class = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:44:21.596864Z","iopub.execute_input":"2021-10-27T18:44:21.597719Z","iopub.status.idle":"2021-10-27T18:44:26.555109Z","shell.execute_reply.started":"2021-10-27T18:44:21.597664Z","shell.execute_reply":"2021-10-27T18:44:26.554083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Third classifier - Exactly as first but with added KFold CV","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfor fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print('-'*10, '>', f'Fold {fold + 1}', '<', '-'*10)\n        \n        X_train, X_valid = X[train_idx], X[test_idx]\n        train_X_df = train_df.loc[train_df[\"img_names\"].isin(list(X_train))]\n        valid_X_df = train_df.loc[train_df[\"img_names\"].isin(list(X_valid))]\n        \n        train_generator_rgb = datagen_rgb.flow_from_dataframe(dataframe=train_X_df,\n                                                             directory=train_rgb, \n                                                             x_col=\"img_names\", \n                                                             y_col=\"fruit_class\",\n                                                             class_mode=\"categorical\", \n                                                             color_mode=\"rgb\",\n                                                             target_size=(128,128),\n                                                             batch_size=32,\n                                                             shuffle=True,\n                                                             seed=42,\n                                                             subset='training'\n                                                             )\n\n        val_generator_rgb = datagen_rgb.flow_from_dataframe(dataframe=train_X_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=True,\n                                                            seed=42,\n                                                            subset='validation',\n                                                            )\n\n        test_generator_rgb = testgen_rgb.flow_from_dataframe(dataframe=valid_X_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=False\n                                                            )\n        \n        model = tf.keras.Sequential()\n        model.add(tf.keras.layers.Conv2D(32, (7, 7), padding='same',\n                         input_shape=(128,128,3), kernel_regularizer=l2(0.0005)))\n        model.add(Activation('relu'))\n        model.add(tf.keras.layers.Conv2D(64, (5, 5), kernel_regularizer=l2(0.0005)))\n        model.add(Activation('relu'))\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(Activation('relu'))\n\n        model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', kernel_regularizer=l2(0.0005)))\n        model.add(Activation('relu'))\n        model.add(tf.keras.layers.Conv2D(256, (5, 5), kernel_regularizer=l2(0.0005)))\n        model.add(Activation('relu'))\n        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.add(Dense(256))\n        model.add(Activation('relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(3, activation='softmax'))\n\n        opt = Adam(lr=1e-4)\n        model.compile(optimizer=opt,\n        loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n        \n        my_callbacks = [EarlyStopping(monitor='val_accuracy',\n                               min_delta=0,\n                               verbose=1,\n                               patience=5,\n                               mode='auto')]\n\n\n        model.fit(train_generator_rgb, \n                  validation_data=val_generator_rgb,\n                  epochs=10,\n                  callbacks=my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:32:32.84013Z","iopub.execute_input":"2021-10-26T16:32:32.840805Z","iopub.status.idle":"2021-10-26T16:39:26.987118Z","shell.execute_reply.started":"2021-10-26T16:32:32.840759Z","shell.execute_reply":"2021-10-26T16:39:26.986349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(val_generator_rgb)\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:40:12.840915Z","iopub.execute_input":"2021-10-26T16:40:12.841651Z","iopub.status.idle":"2021-10-26T16:40:14.780347Z","shell.execute_reply.started":"2021-10-26T16:40:12.84161Z","shell.execute_reply":"2021-10-26T16:40:14.779647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(sub_generator_rgb)\npreds_class = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:40:27.217608Z","iopub.execute_input":"2021-10-26T16:40:27.217895Z","iopub.status.idle":"2021-10-26T16:40:32.609148Z","shell.execute_reply.started":"2021-10-26T16:40:27.21786Z","shell.execute_reply":"2021-10-26T16:40:32.608337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last classifier - Xception model from keras applications. ","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.applications.xception import decode_predictions\nfrom keras.layers import Input\nnew_input = Input(shape=(128, 128, 3))\nxception_model = tf.keras.applications.Xception(include_top=False,\n                                       input_tensor=new_input,\n                                       weights='imagenet',\n                                       classes=3\n                                       )","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:00:25.376768Z","iopub.execute_input":"2021-10-26T16:00:25.377303Z","iopub.status.idle":"2021-10-26T16:00:26.807655Z","shell.execute_reply.started":"2021-10-26T16:00:25.377263Z","shell.execute_reply":"2021-10-26T16:00:26.80693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T13:52:54.942021Z","iopub.execute_input":"2021-10-25T13:52:54.942549Z","iopub.status.idle":"2021-10-25T13:52:55.010837Z","shell.execute_reply.started":"2021-10-25T13:52:54.942513Z","shell.execute_reply":"2021-10-25T13:52:55.010153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.xception import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:00:29.569897Z","iopub.execute_input":"2021-10-26T16:00:29.570593Z","iopub.status.idle":"2021-10-26T16:00:29.574531Z","shell.execute_reply.started":"2021-10-26T16:00:29.570555Z","shell.execute_reply":"2021-10-26T16:00:29.573601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmodel = tf.keras.Sequential()\n\nmodel.add(xception_model)\n\nfor layer in model.layers:\n    layer.trainable = True\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(3, activation='softmax'))\n\nopt = Adam(lr=1e-4)\nmodel.compile(optimizer=opt,\nloss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmy_callbacks = [EarlyStopping(monitor='val_accuracy',\n                       min_delta=0,\n                       verbose=1,\n                       patience=5,\n                       mode='auto')]\n\n\npret_datagen_rgb = tf.keras.preprocessing.image.ImageDataGenerator(\n     rotation_range = 30, zoom_range = 0.20, \n    fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \n    width_shift_range = 0.1, height_shift_range = 0.1,\n    validation_split=0.15, preprocessing_function=preprocess_input)\n\npret_testgen_rgb = tf.keras.preprocessing.image.ImageDataGenerator(\n   rotation_range = 20, zoom_range = 0.1, \n    fill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \n    width_shift_range = 0.1, height_shift_range = 0.1, preprocessing_function=preprocess_input\n)\n\npret_train_generator_rgb = pret_datagen_rgb.flow_from_dataframe(dataframe=train_df,\n                                                             directory=train_rgb, \n                                                             x_col=\"img_names\", \n                                                             y_col=\"fruit_class\",\n                                                             class_mode=\"categorical\", \n                                                             color_mode=\"rgb\",\n                                                             target_size=(128,128),\n                                                             batch_size=32,\n                                                             shuffle=True,\n                                                             seed=42,\n                                                             subset='training'\n                                                             )\n\npret_val_generator_rgb = pret_datagen_rgb.flow_from_dataframe(dataframe=train_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=True,\n                                                            seed=42,\n                                                            subset='validation',\n                                                            )\n\npret_test_generator_rgb = pret_testgen_rgb.flow_from_dataframe(dataframe=val_df,\n                                                            directory=train_rgb, \n                                                            x_col=\"img_names\", \n                                                            y_col=\"fruit_class\",\n                                                            class_mode=\"categorical\", \n                                                            color_mode=\"rgb\",\n                                                            target_size=(128,128),\n                                                            batch_size=32,\n                                                            shuffle=False\n                                                            )\n\nmodel.fit(pret_train_generator_rgb, \n                  validation_data=pret_test_generator_rgb,\n                  epochs=5,\n                  callbacks=my_callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:01:32.121859Z","iopub.execute_input":"2021-10-26T16:01:32.122199Z","iopub.status.idle":"2021-10-26T16:03:26.726712Z","shell.execute_reply.started":"2021-10-26T16:01:32.122166Z","shell.execute_reply":"2021-10-26T16:03:26.726015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(pret_test_generator_rgb)\nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:03:32.2321Z","iopub.execute_input":"2021-10-26T16:03:32.232643Z","iopub.status.idle":"2021-10-26T16:03:35.54214Z","shell.execute_reply.started":"2021-10-26T16:03:32.232599Z","shell.execute_reply":"2021-10-26T16:03:35.541196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(pret_sub_generator_rgb)\npreds_class = np.argmax(preds, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T16:03:57.496258Z","iopub.execute_input":"2021-10-26T16:03:57.496705Z","iopub.status.idle":"2021-10-26T16:04:14.932475Z","shell.execute_reply.started":"2021-10-26T16:03:57.496667Z","shell.execute_reply":"2021-10-26T16:04:14.931681Z"},"trusted":true},"execution_count":null,"outputs":[]}]}