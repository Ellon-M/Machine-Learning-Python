{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-07T02:00:00.759939Z","iopub.execute_input":"2021-10-07T02:00:00.761172Z","iopub.status.idle":"2021-10-07T02:00:00.807562Z","shell.execute_reply.started":"2021-10-07T02:00:00.761017Z","shell.execute_reply":"2021-10-07T02:00:00.806696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\nimport time\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:42:18.385606Z","iopub.execute_input":"2021-10-04T02:42:18.385919Z","iopub.status.idle":"2021-10-04T02:42:28.57695Z","shell.execute_reply.started":"2021-10-04T02:42:18.385888Z","shell.execute_reply":"2021-10-04T02:42:28.575906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"physical_devices = tf.config.list_physical_devices('CPU')\nprint(\"Num CPUs:\", len(physical_devices))\nphysical_devices = tf.config.list_physical_devices('GPU')\nprint(\"Num GPUs:\", len(physical_devices))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:42:28.578857Z","iopub.execute_input":"2021-10-04T02:42:28.579115Z","iopub.status.idle":"2021-10-04T02:42:28.585886Z","shell.execute_reply.started":"2021-10-04T02:42:28.579088Z","shell.execute_reply":"2021-10-04T02:42:28.585005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add more features\n\ndef add_features(df):\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n    \n    df['breath_id_lag'] = df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2'] = df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame'] = np.select([df['breath_id_lag'] == df['breath_id']],[1],0)\n    df['breath_id_lag2same'] = np.select([df['breath_id_lag2'] == df['breath_id']],[1],0)\n    df['u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['u_in_lag'] = df['u_in_lag'] * df['breath_id_lagsame']\n    df['u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['u_in_lag2'] = df['u_in_lag2'] * df['breath_id_lag2same']\n    df['u_out_lag2'] = df['u_out'].shift(2).fillna(0)\n    df['u_out_lag2'] = df['u_out_lag2'] * df['breath_id_lag2same']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['RC'] = df['R'] + df['C']\n    df = pd.get_dummies(df)\n    \n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:42:28.587326Z","iopub.execute_input":"2021-10-04T02:42:28.587539Z","iopub.status.idle":"2021-10-04T02:43:07.210425Z","shell.execute_reply.started":"2021-10-04T02:42:28.587514Z","shell.execute_reply":"2021-10-04T02:43:07.20944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\nprint(targets)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:43:07.213241Z","iopub.execute_input":"2021-10-04T02:43:07.213786Z","iopub.status.idle":"2021-10-04T02:43:07.953327Z","shell.execute_reply.started":"2021-10-04T02:43:07.213731Z","shell.execute_reply":"2021-10-04T02:43:07.952683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['pressure','breath_id', 'one', 'count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1, inplace=True)\ntest = test.drop(['breath_id','one', 'count','breath_id_lag','breath_id_lag2','breath_id_lagsame','breath_id_lag2same','u_out_lag2'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:43:07.954327Z","iopub.execute_input":"2021-10-04T02:43:07.955137Z","iopub.status.idle":"2021-10-04T02:43:08.765494Z","shell.execute_reply.started":"2021-10-04T02:43:07.955102Z","shell.execute_reply":"2021-10-04T02:43:08.764687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standardization - centering and scaling\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:43:08.767277Z","iopub.execute_input":"2021-10-04T02:43:08.767588Z","iopub.status.idle":"2021-10-04T02:43:13.155912Z","shell.execute_reply.started":"2021-10-04T02:43:08.76755Z","shell.execute_reply":"2021-10-04T02:43:13.155179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 300\nBATCH_SIZE = 128\n\n# detecting and initializing the tpu (tensor processing unit)\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n    test_preds = []\n    \n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold + 1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        \n        model = keras.models.Sequential([\n            keras.layers.Input(shape = train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(300, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences = True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences = True)),\n             keras.layers.Dense(50, activation='selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer = \"adam\", loss = \"mae\")\n        \n        scheduler = ExponentialDecay(1e-3, 400*((len(train) * 0.8)/ BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose = 1)\n        \n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr])\n        \n        # preds\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","metadata":{"execution":{"iopub.status.busy":"2021-10-04T02:43:13.15822Z","iopub.execute_input":"2021-10-04T02:43:13.158552Z","iopub.status.idle":"2021-10-04T10:29:10.670051Z","shell.execute_reply.started":"2021-10-04T02:43:13.15851Z","shell.execute_reply":"2021-10-04T10:29:10.668001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['pressure'] = sum(test_preds)/5\nsubmission.to_csv('submission7.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T10:29:49.235799Z","iopub.execute_input":"2021-10-04T10:29:49.236098Z","iopub.status.idle":"2021-10-04T10:30:01.041122Z","shell.execute_reply.started":"2021-10-04T10:29:49.236068Z","shell.execute_reply":"2021-10-04T10:30:01.040161Z"},"trusted":true},"execution_count":null,"outputs":[]}]}